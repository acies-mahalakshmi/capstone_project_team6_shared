{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging jan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name Employee ID        Designation  \\\n",
      "0  18-01-2024 00:00   Alexander Cole        2080          Associate   \n",
      "1  15-01-2024 00:00   Miles Martinez        2017  Software Engineer   \n",
      "2  16-01-2024 00:00  Felicity Taylor        2078         Associate    \n",
      "3  19-01-2024 00:00  Savannah Taylor        1870    Engagement Lead   \n",
      "4  17-01-2024 00:00     Mabel Gibson        2008  Software Engineer   \n",
      "\n",
      "  Project Name            Email address  Total Persons  Allowable Amount  \\\n",
      "0          NaN   Alexander.Cole@xyz.com              1               400   \n",
      "1    Greenmath   Miles.Martinez@xyz.com             19              7600   \n",
      "2          GPC  Felicity.Taylor@xyz.com              1               400   \n",
      "3  edgeCore.ai  Savannah.Taylor@xyz.com             10              4000   \n",
      "4    greenMath     Mabel.Gibson@xyz.com              4              1600   \n",
      "\n",
      "   Total Bill Amount                          List of Persons (as JSON)  \\\n",
      "0                321  [{\"employee_code\": \"2080\", \"name\": \"Alexander ...   \n",
      "1               7647  [{\"employee_code\": \"2005\", \"name\": \"Zoe Sulliv...   \n",
      "2                380  [{\"employee_code\": \"2078\", \"name\": \"Felicity T...   \n",
      "3               3941  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "4               1700  [{\"employee_code\": \"2008\", \"name\": \"Mabel Gibs...   \n",
      "\n",
      "                                                Bill     Seating Location  \n",
      "0  [{\"Bill_Date\": \"2024-01-03\", \"Bill_No\": \"01_12...  Workafella, Chennai  \n",
      "1  [{\"Bill_Date\": \"2024-01-02\", \"Bill_No\": \"01_37...            Bangalore  \n",
      "2  [{\"Bill_Date\": \"2024-01-03\", \"Bill_No\": \"01_16...  Workafella, Chennai  \n",
      "3  [{\"Bill_Date\": \"2024-01-17\", \"Bill_No\": \"01_14...  Workafella, Chennai  \n",
      "4  [{\"Bill_Date\": \"2024-01-06\", \"Bill_No\": \"01_55...  Workafella, Chennai  \n",
      "Number of matched Employee IDs: 653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(\"Reimbursement(Jan-Sep).csv\")\n",
    "df2 = pd.read_csv(\"employee_details.csv\")\n",
    "\n",
    "# Rename \"Employee\" column to \"Employee ID\" in df2\n",
    "df2.rename(columns={\"Employee\": \"Employee ID\"}, inplace=True)\n",
    "\n",
    "# Standardize Employee ID formatting (strip spaces)\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].astype(str).str.strip()\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].astype(str).str.strip()\n",
    "\n",
    "# Convert Employee ID to consistent format (handling non-numeric values)\n",
    "df1[\"Employee ID\"] = pd.to_numeric(df1[\"Employee ID\"], errors='coerce')  # convert to numeric, set errors to NaN\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "df2[\"Employee ID\"] = pd.to_numeric(df2[\"Employee ID\"], errors='coerce')  # same for df2\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "# Merge on Employee ID\n",
    "df_merged = df1.merge(df2[[\"Employee ID\", \"Seating Location\"]], on=\"Employee ID\", how=\"left\")\n",
    "\n",
    "# Save the updated dataset\n",
    "df_merged.to_csv(\"merged_data_jan_sep.csv\", index=False)\n",
    "\n",
    "# Debugging info\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check how many matched Employee IDs\n",
    "matched = df_merged[\"Seating Location\"].notna().sum()\n",
    "print(f\"Number of matched Employee IDs: {matched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name Employee ID            Designation  \\\n",
      "0  21-10-2024 00:00       Abel Lopez        1959         People Partner   \n",
      "1  21-10-2024 00:00  Savannah Taylor        1870  Senior Data Scientist   \n",
      "2  10-10-2024 00:00  Savannah Taylor        1870  Senior Data Scientist   \n",
      "3  10-10-2024 00:00  Savannah Taylor        1870  Senior Data Scientist   \n",
      "4  10-10-2024 00:00  Savannah Taylor        1870  Senior Data Scientist   \n",
      "\n",
      "  Project Name            Email address  Total Persons  Allowable Amount  \\\n",
      "0           HR       Abel.Lopez@xyz.com              2               800   \n",
      "1  edgeCore.ai  Savannah.Taylor@xyz.com              6              2400   \n",
      "2  edgeCore.ai  Savannah.Taylor@xyz.com              2               800   \n",
      "3  edgeCore.ai  Savannah.Taylor@xyz.com              2               800   \n",
      "4  edgeCore.ai  Savannah.Taylor@xyz.com              2               800   \n",
      "\n",
      "   Total Bill Amount                          List of Persons (as JSON)  \\\n",
      "0              777.0  [{\"employee_code\": \"1959\", \"name\": \"Abel Lopez...   \n",
      "1             2588.0  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "2              882.0  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "3              882.0  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "4              882.0  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "\n",
      "                                                Bill     Seating Location  \n",
      "0  [{\"Bill_Date\": \"2024-10-10 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "1  [{\"Bill_Date\": \"2024-10-18 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "2  [{\"Bill_Date\": \"2024-10-04 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "3  [{\"Bill_Date\": \"2024-10-04 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "4  [{\"Bill_Date\": \"2024-10-04 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "Number of matched Employee IDs: 39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(\"Reimbursement(Oct).csv\")\n",
    "df2 = pd.read_csv(\"employee_details.csv\")\n",
    "\n",
    "# Rename \"Employee\" column to \"Employee ID\" in df2\n",
    "df2.rename(columns={\"Employee\": \"Employee ID\"}, inplace=True)\n",
    "\n",
    "# Standardize Employee ID formatting (strip spaces)\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].astype(str).str.strip()\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].astype(str).str.strip()\n",
    "\n",
    "# Convert Employee ID to consistent format (handling non-numeric values)\n",
    "df1[\"Employee ID\"] = pd.to_numeric(df1[\"Employee ID\"], errors='coerce')  # convert to numeric, set errors to NaN\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "df2[\"Employee ID\"] = pd.to_numeric(df2[\"Employee ID\"], errors='coerce')  # same for df2\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "# Merge on Employee ID\n",
    "df_merged = df1.merge(df2[[\"Employee ID\", \"Seating Location\"]], on=\"Employee ID\", how=\"left\")\n",
    "\n",
    "# Save the updated dataset\n",
    "df_merged.to_csv(\"merged_data_oct.csv\", index=False)\n",
    "\n",
    "# Debugging info\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check how many matched Employee IDs\n",
    "matched = df_merged[\"Seating Location\"].notna().sum()\n",
    "print(f\"Number of matched Employee IDs: {matched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name Employee ID      Designation  \\\n",
      "0  21-11-2024 00:00  Savannah Taylor        1870  Engagement Lead   \n",
      "1  21-11-2024 00:00  Savannah Taylor        1870  Engagement Lead   \n",
      "2  30-11-2024 00:00  Savannah Taylor        1870  Engagement Lead   \n",
      "3  30-11-2024 00:00  Savannah Taylor        1870  Engagement Lead   \n",
      "4        20-11-2024       Nia Thomas        2068    Data Engineer   \n",
      "\n",
      "         Project Name            Email address  Total Persons  \\\n",
      "0         edgeCore.ai  Savannah.Taylor@xyz.com              3   \n",
      "1         edgeCore.ai  Savannah.Taylor@xyz.com              3   \n",
      "2  edgeCore.ai / Bose  Savannah.Taylor@xyz.com              8   \n",
      "3  edgeCore.ai / Bose  Savannah.Taylor@xyz.com              8   \n",
      "4                   -       Nia.Thomas@xyz.com              5   \n",
      "\n",
      "   Allowable Amount Total Bill Amount  \\\n",
      "0              1200              2153   \n",
      "1              1200              2153   \n",
      "2              3200              6033   \n",
      "3              3200              6033   \n",
      "4              2000              2160   \n",
      "\n",
      "                           List of Persons (as JSON)  \\\n",
      "0  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "1  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "2  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "3  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "4  [{\"employee_code\": \"2068\", \"name\": \"Nia Thomas...   \n",
      "\n",
      "                                                Bill     Seating Location  \n",
      "0  [{\"Bill_Date\": \"2024-11-01 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "1  [{\"Bill_Date\": \"2024-11-01 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "2  [{\"Bill_Date\": \"2024-11-22 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "3  [{\"Bill_Date\": \"2024-11-22 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "4  [{\"Bill_Date\": \"15-11-2024\", \"Bill_No\": 746142...  Workafella, Chennai  \n",
      "Number of matched Employee IDs: 56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(\"Reimbursement(Nov).csv\")\n",
    "df2 = pd.read_csv(\"employee_details.csv\")\n",
    "\n",
    "# Rename \"Employee\" column to \"Employee ID\" in df2\n",
    "df2.rename(columns={\"Employee\": \"Employee ID\"}, inplace=True)\n",
    "\n",
    "# Standardize Employee ID formatting (strip spaces)\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].astype(str).str.strip()\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].astype(str).str.strip()\n",
    "\n",
    "# Convert Employee ID to consistent format (handling non-numeric values)\n",
    "df1[\"Employee ID\"] = pd.to_numeric(df1[\"Employee ID\"], errors='coerce')  # convert to numeric, set errors to NaN\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "df2[\"Employee ID\"] = pd.to_numeric(df2[\"Employee ID\"], errors='coerce')  # same for df2\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "# Merge on Employee ID\n",
    "df_merged = df1.merge(df2[[\"Employee ID\", \"Seating Location\"]], on=\"Employee ID\", how=\"left\")\n",
    "\n",
    "# Save the updated dataset\n",
    "df_merged.to_csv(\"merged_data_nov.csv\", index=False)\n",
    "\n",
    "# Debugging info\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check how many matched Employee IDs\n",
    "matched = df_merged[\"Seating Location\"].notna().sum()\n",
    "print(f\"Number of matched Employee IDs: {matched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name Employee ID      Designation  \\\n",
      "0  03-01-2025 00:00       Luca Allen        1957              STL   \n",
      "1  03-01-2025 00:00       Luca Allen        1957              STL   \n",
      "2  03-01-2025 00:00       Luca Allen        1957              STL   \n",
      "3  03-01-2025 00:00       Luca Allen        1957              STL   \n",
      "4  30-12-2024 00:00  Savannah Taylor        1870  Engagement Lead   \n",
      "\n",
      "          Project Name            Email address  Total Persons  \\\n",
      "0  edgeCore, GreenMath       Luca.Allen@xyz.com             10   \n",
      "1  edgeCore, GreenMath       Luca.Allen@xyz.com             10   \n",
      "2  edgeCore, GreenMath       Luca.Allen@xyz.com             10   \n",
      "3  edgeCore, GreenMath       Luca.Allen@xyz.com             10   \n",
      "4          edgeCore.ai  Savannah.Taylor@xyz.com             11   \n",
      "\n",
      "   Allowable Amount  Total Bill Amount  \\\n",
      "0              4000             4863.0   \n",
      "1              4000             4863.0   \n",
      "2              4000             4863.0   \n",
      "3              4000             4863.0   \n",
      "4              4400             5506.0   \n",
      "\n",
      "                           List of Persons (as JSON)  \\\n",
      "0  [{\"employee_code\": \"1957\", \"name\": \"Luca Allen...   \n",
      "1  [{\"employee_code\": \"1957\", \"name\": \"Luca Allen...   \n",
      "2  [{\"employee_code\": \"1957\", \"name\": \"Luca Allen...   \n",
      "3  [{\"employee_code\": \"1957\", \"name\": \"Luca Allen...   \n",
      "4  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "\n",
      "                                                Bill     Seating Location  \n",
      "0  [{\"Bill_Date\": \"2025-01-03 00:00:00\", \"Bill_No...     Bhive, Bangalore  \n",
      "1  [{\"Bill_Date\": \"2025-01-03 00:00:00\", \"Bill_No...     Bhive, Bangalore  \n",
      "2  [{\"Bill_Date\": \"2025-01-03 00:00:00\", \"Bill_No...     Bhive, Bangalore  \n",
      "3  [{\"Bill_Date\": \"2025-01-03 00:00:00\", \"Bill_No...     Bhive, Bangalore  \n",
      "4  [{\"Bill_Date\": \"2024-12-27 00:00:00\", \"Bill_No...  Workafella, Chennai  \n",
      "Number of matched Employee IDs: 38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(\"Reimbursement(Dec).csv\")\n",
    "df2 = pd.read_csv(\"employee_details.csv\")\n",
    "\n",
    "# Rename \"Employee\" column to \"Employee ID\" in df2\n",
    "df2.rename(columns={\"Employee\": \"Employee ID\"}, inplace=True)\n",
    "\n",
    "# Standardize Employee ID formatting (strip spaces)\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].astype(str).str.strip()\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].astype(str).str.strip()\n",
    "\n",
    "# Convert Employee ID to consistent format (handling non-numeric values)\n",
    "df1[\"Employee ID\"] = pd.to_numeric(df1[\"Employee ID\"], errors='coerce')  # convert to numeric, set errors to NaN\n",
    "df1[\"Employee ID\"] = df1[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "df2[\"Employee ID\"] = pd.to_numeric(df2[\"Employee ID\"], errors='coerce')  # same for df2\n",
    "df2[\"Employee ID\"] = df2[\"Employee ID\"].fillna(0).astype(\"Int64\").astype(str)  # fill NaNs with 0 and convert to string\n",
    "\n",
    "# Merge on Employee ID\n",
    "df_merged = df1.merge(df2[[\"Employee ID\", \"Seating Location\"]], on=\"Employee ID\", how=\"left\")\n",
    "\n",
    "# Save the updated dataset\n",
    "df_merged.to_csv(\"merged_data_dec.csv\", index=False)\n",
    "\n",
    "# Debugging info\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check how many matched Employee IDs\n",
    "matched = df_merged[\"Seating Location\"].notna().sum()\n",
    "print(f\"Number of matched Employee IDs: {matched}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name  Employee ID        Designation  \\\n",
      "0  18-01-2024 00:00   Alexander Cole         2080          Associate   \n",
      "1  15-01-2024 00:00   Miles Martinez         2017  Software Engineer   \n",
      "2  16-01-2024 00:00  Felicity Taylor         2078         Associate    \n",
      "3  19-01-2024 00:00  Savannah Taylor         1870    Engagement Lead   \n",
      "4  17-01-2024 00:00     Mabel Gibson         2008  Software Engineer   \n",
      "\n",
      "  Project Name            Email address  Total Persons  Allowable Amount  \\\n",
      "0          NaN   Alexander.Cole@xyz.com              1               400   \n",
      "1    Greenmath   Miles.Martinez@xyz.com             19              7600   \n",
      "2          GPC  Felicity.Taylor@xyz.com              1               400   \n",
      "3  edgeCore.ai  Savannah.Taylor@xyz.com             10              4000   \n",
      "4    greenMath     Mabel.Gibson@xyz.com              4              1600   \n",
      "\n",
      "  Total Bill Amount                          List of Persons (as JSON)  \\\n",
      "0               321  [{\"employee_code\": \"2080\", \"name\": \"Alexander ...   \n",
      "1              7647  [{\"employee_code\": \"2005\", \"name\": \"Zoe Sulliv...   \n",
      "2               380  [{\"employee_code\": \"2078\", \"name\": \"Felicity T...   \n",
      "3              3941  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "4              1700  [{\"employee_code\": \"2008\", \"name\": \"Mabel Gibs...   \n",
      "\n",
      "                                                Bill     Seating Location  \n",
      "0  [{\"Bill_Date\": \"2024-01-03\", \"Bill_No\": \"01_12...  Workafella, Chennai  \n",
      "1  [{\"Bill_Date\": \"2024-01-02\", \"Bill_No\": \"01_37...            Bangalore  \n",
      "2  [{\"Bill_Date\": \"2024-01-03\", \"Bill_No\": \"01_16...  Workafella, Chennai  \n",
      "3  [{\"Bill_Date\": \"2024-01-17\", \"Bill_No\": \"01_14...  Workafella, Chennai  \n",
      "4  [{\"Bill_Date\": \"2024-01-06\", \"Bill_No\": \"01_55...  Workafella, Chennai  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets for each month\n",
    "df_jan = pd.read_csv(\"merged_data_jan_sep.csv\")  # January data\n",
    "df_oct = pd.read_csv(\"merged_data_oct.csv\")  # October data\n",
    "df_nov = pd.read_csv(\"merged_data_nov.csv\")  # November data\n",
    "df_dec = pd.read_csv(\"merged_data_dec.csv\")  # December data\n",
    "\n",
    "# List all datasets to combine\n",
    "dfs = [df_jan, df_oct, df_nov, df_dec]\n",
    "\n",
    "# Concatenate datasets vertically (row-wise)\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "df_combined.to_csv(\"Reimbursement_combined.csv\", index=False)\n",
    "\n",
    "# Display the combined dataset (for verification)\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted the Json values in the Bill column based on the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as transformed_Bill.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"Reimbursement_combined.csv\")  # Replace with your actual filename\n",
    "\n",
    "\n",
    "# Convert 'Bill' column from string to a list of dictionaries\n",
    "df[\"Bill\"] = df[\"Bill\"].apply(lambda x: json.loads(x)[0])  # Extract first dictionary\n",
    "\n",
    "# Expand JSON columns\n",
    "df_expanded = df[\"Bill\"].apply(pd.Series)\n",
    "\n",
    "# Merge with original data (if needed) and remove the original 'Bill' column\n",
    "df_final = df.drop(columns=[\"Bill\"]).join(df_expanded)\n",
    "\n",
    "# Save to a new CSV file\n",
    "df_final.to_csv(\"transformed_Bill.csv\", index=False)\n",
    "\n",
    "print(\"File saved as transformed_Bill.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seating location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"transformed_Bill.csv\")\n",
    "df['Seating Location'] = df['Seating Location'].replace('Workafella, Chennai', 'Chennai')\n",
    "df['Seating Location'] = df['Seating Location'].replace('Bhive, Bangalore', 'Bangalore')\n",
    "df.to_csv(\"transformed_Bill.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Claim Date    Employee Name  Employee ID        Designation  \\\n",
      "0  18-01-2024 00:00   Alexander Cole         2080          Associate   \n",
      "1  15-01-2024 00:00   Miles Martinez         2017  Software Engineer   \n",
      "2  16-01-2024 00:00  Felicity Taylor         2078         Associate    \n",
      "3  19-01-2024 00:00  Savannah Taylor         1870    Engagement Lead   \n",
      "4  17-01-2024 00:00     Mabel Gibson         2008  Software Engineer   \n",
      "\n",
      "  Project Name            Email address  Total Persons  Allowable Amount  \\\n",
      "0          NaN   Alexander.Cole@xyz.com              1               400   \n",
      "1    Greenmath   Miles.Martinez@xyz.com             19              7600   \n",
      "2          GPC  Felicity.Taylor@xyz.com              1               400   \n",
      "3  edgeCore.ai  Savannah.Taylor@xyz.com             10              4000   \n",
      "4    greenMath     Mabel.Gibson@xyz.com              4              1600   \n",
      "\n",
      "  Total Bill Amount                          List of Persons (as JSON)  \\\n",
      "0               321  [{\"employee_code\": \"2080\", \"name\": \"Alexander ...   \n",
      "1              7647  [{\"employee_code\": \"2005\", \"name\": \"Zoe Sulliv...   \n",
      "2               380  [{\"employee_code\": \"2078\", \"name\": \"Felicity T...   \n",
      "3              3941  [{\"employee_code\": \"1870\", \"name\": \"Savannah T...   \n",
      "4              1700  [{\"employee_code\": \"2008\", \"name\": \"Mabel Gibs...   \n",
      "\n",
      "  Seating Location   Bill_Date Bill_No Total_Price  \n",
      "0          Chennai  2024-01-03  01_124         321  \n",
      "1        Bangalore  2024-01-02   01_37        7647  \n",
      "2          Chennai  2024-01-03  01_163         380  \n",
      "3          Chennai  2024-01-17  01_142        3941  \n",
      "4          Chennai  2024-01-06   01_55        1700  \n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Error parsing JSON: 'float' object has no attribute 'replace'\n",
      "Total Entries: 13555\n",
      "Valid Employee Codes: 4879\n",
      "Valid Names: 13073\n",
      "Total Unique Employees: 93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"transformed_Bill.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the JSON is inside a column named 'persons_data'\n",
    "json_column = \"List of Persons (as JSON)\"  # Replace with the actual column name\n",
    "\n",
    "# Function to extract employee_code and name from JSON column\n",
    "def extract_employee_details(json_str):\n",
    "    try:\n",
    "        # Parse JSON string into a Python list of dictionaries\n",
    "        employees = json.loads(json_str.replace(\"'\", \"\\\"\"))  # Handle single quotes if needed\n",
    "        \n",
    "        # Extract employee_code and name from each dictionary\n",
    "        return [(emp.get(\"employee_code\", None), emp.get(\"name\", None)) for emp in employees]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return []  # Return empty list if JSON parsing fails\n",
    "\n",
    "# Apply function and explode to create individual rows\n",
    "df[\"employee_details\"] = df[json_column].apply(extract_employee_details)\n",
    "df = df.explode(\"employee_details\")\n",
    "\n",
    "# Convert tuple columns into separate columns\n",
    "df[[\"employee_code\", \"name\"]] = pd.DataFrame(df[\"employee_details\"].tolist(), index=df.index)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"employee_details\", json_column])\n",
    "\n",
    "# Count valid values\n",
    "valid_employee_code = df[\"employee_code\"].notna().sum()\n",
    "valid_name = df[\"name\"].notna().sum()\n",
    "\n",
    "print(f\"Total Entries: {len(df)}\")\n",
    "print(f\"Valid Employee Codes: {valid_employee_code}\")\n",
    "print(f\"Valid Names: {valid_name}\")\n",
    "\n",
    "# Count unique employees\n",
    "unique_employees = df.dropna(subset=[\"employee_code\", \"name\"]).drop_duplicates(subset=[\"employee_code\", \"name\"])\n",
    "print(f\"Total Unique Employees: {len(unique_employees)}\")\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv(\"processed_employees.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Inconsistencies found! The following Employee IDs have multiple names or designations:\n",
      "            Claim Date    Employee Name  Employee ID            Designation  \\\n",
      "3      19 January 2024  Savannah Taylor       1870.0        Engagement Lead   \n",
      "8      28 January 2024  Savannah Taylor       1870.0  Senior Data Scientist   \n",
      "11     25 January 2024  Savannah Taylor       1870.0  Senior Data Scientist   \n",
      "12     26 January 2024   Felicity Craig          0.0                 intern   \n",
      "13     26 January 2024   Felicity Craig          0.0                 intern   \n",
      "...                ...              ...          ...                    ...   \n",
      "1166  20 December 2024      Miles Lynch          0.0                 Intern   \n",
      "1167  20 December 2024      Miles Lynch          0.0                 Intern   \n",
      "1185  28 December 2024   Vivian Johnson       2029.0   Senior Data Engineer   \n",
      "1186  28 December 2024   Vivian Johnson       2029.0   Senior Data Engineer   \n",
      "1187  24 December 2024   Vivian Johnson       2029.0          Data Engineer   \n",
      "\n",
      "                Project Name            Email address  Total Persons  \\\n",
      "3                edgeCore.ai  Savannah.Taylor@xyz.com           10.0   \n",
      "8                edgeCore.ai  Savannah.Taylor@xyz.com            2.0   \n",
      "11               edgeCore.ai  Savannah.Taylor@xyz.com            6.0   \n",
      "12                        o9   Felicity.Craig@xyz.com            1.0   \n",
      "13                        o9   Felicity.Craig@xyz.com            1.0   \n",
      "...                      ...                      ...            ...   \n",
      "1166                 Traning      Miles.Lynch@xyz.com            2.0   \n",
      "1167                 Traning      Miles.Lynch@xyz.com            2.0   \n",
      "1185                      o9   Vivian.Johnson@xyz.com            7.0   \n",
      "1186                      o9   Vivian.Johnson@xyz.com            7.0   \n",
      "1187  o9 -  TMobile Resilinc   Vivian.Johnson@xyz.com            1.0   \n",
      "\n",
      "      Allowable Amount Total Bill Amount  \\\n",
      "3               4000.0              3941   \n",
      "8                800.0               896   \n",
      "11              2400.0              2392   \n",
      "12               400.0               379   \n",
      "13               400.0               379   \n",
      "...                ...               ...   \n",
      "1166             800.0              1021   \n",
      "1167             800.0              1021   \n",
      "1185            2800.0              3638   \n",
      "1186            2800.0              3638   \n",
      "1187             400.0               409   \n",
      "\n",
      "                              List of Persons (as JSON) Seating Location  \\\n",
      "3     [{\"employee_code\": \"1870\", \"name\": \"Savannah T...          Chennai   \n",
      "8     [{\"employee_code\": \"1870\", \"name\": \"Savannah T...          Chennai   \n",
      "11    [{\"employee_code\": \"1870\", \"name\": \"Savannah T...          Chennai   \n",
      "12    [{\"employee_code\": NaN, \"name\": \"Autumn Hughes...              NaN   \n",
      "13    [{\"employee_code\": NaN, \"name\": \"Autumn Hughes...              NaN   \n",
      "...                                                 ...              ...   \n",
      "1166  [{\"employee_code\": NaN, \"name\": NaN}, {\"employ...              NaN   \n",
      "1167  [{\"employee_code\": NaN, \"name\": NaN}, {\"employ...              NaN   \n",
      "1185  [{\"employee_code\": \"2029\", \"name\": \"Vivian Joh...          Chennai   \n",
      "1186  [{\"employee_code\": \"2029\", \"name\": \"Vivian Joh...          Chennai   \n",
      "1187  [{\"employee_code\": \"2029\", \"name\": \"Vivian Joh...          Chennai   \n",
      "\n",
      "             Bill_Date              Bill_No Total_Price  \n",
      "3           17-01-2024               01_142        3941  \n",
      "8           09-01-2024                 01_3         896  \n",
      "11          18-01-2024                 01_2        2392  \n",
      "12          09-01-2024                01_73         379  \n",
      "13          09-01-2024                01_73         379  \n",
      "...                ...                  ...         ...  \n",
      "1166        20-12-2024  2117201224024410000        1021  \n",
      "1167        20-12-2024  2117201224024410000        1021  \n",
      "1185  27-12-2024 00:00      20241227_165916        3638  \n",
      "1186  27-12-2024 00:00      20241227_165916        3638  \n",
      "1187  20-12-2024 00:00      193649043704089         409  \n",
      "\n",
      "[559 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# Load the CSV file\n",
    "file_path = \"transformed_Bill.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group by employee_id and check unique combinations of (name, designation)\n",
    "duplicates = df.groupby(\"Employee ID\")[[\"Employee Name\", \"Designation\"]].nunique()\n",
    "\n",
    "# Identify Employee IDs where either Name or Designation is inconsistent\n",
    "inconsistent_ids = duplicates[(duplicates[\"Employee Name\"] > 1) | (duplicates[\"Designation\"] > 1)].index\n",
    "\n",
    "# Extract rows with inconsistencies\n",
    "inconsistent_rows = df[df[\"Employee ID\"].isin(inconsistent_ids)]\n",
    "\n",
    "# Display results\n",
    "if inconsistent_rows.empty:\n",
    "    print(\"✅ All Employee IDs consistently match the same Employee Name and Designation.\")\n",
    "else:\n",
    "    print(\"⚠️ Inconsistencies found! The following Employee IDs have multiple names or designations:\")\n",
    "    print(inconsistent_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Inconsistencies found! The affected records have been saved in 'inconsistent_employees.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"transformed_Bill.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group by employee_id and check unique counts for (name, designation)\n",
    "duplicates = df.groupby(\"Employee ID\")[[\"Employee Name\"]].nunique()\n",
    "\n",
    "# Identify Employee IDs where either Name or Designation is inconsistent\n",
    "inconsistent_ids = duplicates[(duplicates[\"Employee Name\"] > 1)].index\n",
    "\n",
    "# Extract inconsistent rows\n",
    "inconsistent_rows = df[df[\"Employee ID\"].isin(inconsistent_ids)]\n",
    "\n",
    "# Save the inconsistent records to a separate CSV file\n",
    "output_file = \"inconsistent_employees.csv\"\n",
    "inconsistent_rows.to_csv(output_file, index=False)\n",
    "\n",
    "# Display results\n",
    "if inconsistent_rows.empty:\n",
    "    print(\"✅ All Employee IDs consistently match the same Employee Name and Designation.\")\n",
    "else:\n",
    "    print(f\"⚠️ Inconsistencies found! The affected records have been saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completely blank rows removed. Cleaned file saved as 'Reimbursement_Cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "cleaned_df = pd.read_csv(\"Reimbursement_cleaned_data.csv\")\n",
    "\n",
    "# Remove rows where ALL columns are blank\n",
    "df_cleaned = cleaned_df.dropna(how='all')\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_cleaned.to_csv(\"Reimbursement_cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"Completely blank rows removed. Cleaned file saved as 'Reimbursement_Cleaned.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Date                    0\n",
       "Employee Name                 0\n",
       "Employee ID                   0\n",
       "Designation                   0\n",
       "Project Name                 80\n",
       "Email address                 1\n",
       "Total Persons                 0\n",
       "Allowable Amount              0\n",
       "Total Bill Amount             0\n",
       "List of Persons (as JSON)    19\n",
       "Seating Location             66\n",
       "Bill_Date                     0\n",
       "Bill_No                       2\n",
       "Bill day                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch column added. Updated dataset saved as 'Reimbursement_Updated.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"Reimbursement_cleaned_data.csv\")\n",
    "\n",
    "# Function to count employee codes in JSON list\n",
    "def count_persons(json_str):\n",
    "    try:\n",
    "        persons_list = json.loads(json_str)  # Convert JSON string to Python list\n",
    "        return len(persons_list) if isinstance(persons_list, list) else 0\n",
    "    except (json.JSONDecodeError, TypeError):  # Handle errors\n",
    "        return 0\n",
    "\n",
    "# Apply function to count persons and add to dataset\n",
    "df['Computed_Total_Persons'] = df['List of Persons (as JSON)'].apply(count_persons)\n",
    "\n",
    "# Check if Computed_Total_Persons matches Total Persons and add Mismatch column\n",
    "df['Mismatch'] = df['Computed_Total_Persons'] != df['Total Persons']\n",
    "\n",
    "# Save the updated dataset with Mismatch column\n",
    "df.to_csv(\"Reimbursement_cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"Mismatch column added. Updated dataset saved as 'Reimbursement_Updated.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
