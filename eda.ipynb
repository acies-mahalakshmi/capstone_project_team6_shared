{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Reimbursement_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique rows: 786\n"
     ]
    }
   ],
   "source": [
    "num_unique_rows = df.drop_duplicates().shape[0]\n",
    "print(f\"Number of unique rows: {num_unique_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bill Dates in the future compared to Claim Date: 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DYNABOOK\\AppData\\Local\\Temp\\ipykernel_2308\\1909333884.py:6: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['Claim Date'] = pd.to_datetime(df['Claim Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"cleaned_file.csv\"  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df['Claim Date'] = pd.to_datetime(df['Claim Date'], errors='coerce')\n",
    "df['Bill_Date'] = pd.to_datetime(df['Bill_Date'], errors='coerce')\n",
    "\n",
    "# Find rows where Bill Date is in the future compared to Claim Date\n",
    "future_bill_dates = df[df['Bill_Date'] > df['Claim Date']]\n",
    "\n",
    "# Count the number of such occurrences\n",
    "num_future_bills = len(future_bill_dates)\n",
    "\n",
    "print(f\"Number of Bill Dates in the future compared to Claim Date: {num_future_bills}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bill Dates that are not Fridays: 67\n"
     ]
    }
   ],
   "source": [
    "# Find rows where Bill Date is NOT a Friday\n",
    "non_friday_bills = df[df['Bill_Date'].dt.day_name() == 'Friday']\n",
    "\n",
    "# Count the number of such occurrences\n",
    "num_non_friday_bills = len(non_friday_bills)\n",
    "\n",
    "print(f\"Number of Bill Dates that are not Fridays: {num_non_friday_bills}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18-01-2024' '15-01-2024' '16-01-2024' '19-01-2024' '17-01-2024'\n",
      " '27-01-2024' '24-01-2024' '23-01-2024' '28-01-2024' '06-01-2024'\n",
      " '29-01-2024' '25-01-2024' '26-01-2024' '20-01-2024' '05-01-2024'\n",
      " '13-01-2024' '22-01-2024' '09-01-2024' '07-01-2024' '14-01-2024'\n",
      " '21-01-2024' '10-01-2024' '30-01-2024' '12-01-2024' '11-01-2024'\n",
      " '04-02-2024' '21-02-2024' '14-02-2024' '09-02-2024' '16-02-2024'\n",
      " '26-02-2024' '30-02-2024' '29-02-2024' '25-02-2024' '15-02-2024'\n",
      " '02-02-2024' '19-02-2024' '11-02-2024' '24-02-2024' '20-02-2024'\n",
      " '22-02-2024' '27-02-2024' '23-02-2024' '18-02-2024' '05-02-2024'\n",
      " '08-02-2024' '28-02-2024' '07-02-2024' '12-02-2024' '13-02-2024'\n",
      " '21-03-2024' '27-03-2024' '23-03-2024' '22-03-2024' '25-03-2024'\n",
      " '24-03-2024' '12-03-2024' '29-03-2024' '18-03-2024' '30-03-2024'\n",
      " '05-03-2024' '20-03-2024' '28-03-2024' '26-03-2024' '17-03-2024'\n",
      " '15-03-2024' '10-03-2024' '16-03-2024' '14-03-2024' '07-03-2024'\n",
      " '13-03-2024' '09-03-2024' '19-03-2024' '06-03-2024' '11-03-2024'\n",
      " '08-03-2024' '28-04-2024' '18-04-2024' '24-04-2024' '15-04-2024'\n",
      " '13-04-2024' '17-04-2024' '19-04-2024' '22-04-2024' '07-04-2024'\n",
      " '29-04-2024' '25-04-2024' '16-04-2024' '30-04-2024' '26-04-2024'\n",
      " '21-04-2024' '11-04-2024' '20-04-2024' '27-04-2024' '23-04-2024'\n",
      " '14-04-2024' '06-04-2024' '12-04-2024' '03-04-2024' '09-04-2024'\n",
      " '05-04-2024' '18-05-2024' '08-05-2024' '29-05-2024' '12-05-2024'\n",
      " '14-05-2024' '30-05-2024' '09-05-2024' '23-05-2024' '19-05-2024'\n",
      " '17-05-2024' '21-05-2024' '24-05-2024' '20-05-2024' '27-05-2024'\n",
      " '28-05-2024' '16-05-2024' '26-05-2024' '07-05-2024' '11-05-2024'\n",
      " '22-05-2024' '25-05-2024' '10-05-2024' '18-06-2024' '13-06-2024'\n",
      " '04-06-2024' '29-06-2024' '14-06-2024' '27-06-2024' '23-06-2024'\n",
      " '30-06-2024' '21-06-2024' '17-06-2024' '19-06-2024' '28-06-2024'\n",
      " '08-06-2024' '25-06-2024' '09-06-2024' '26-06-2024' '20-06-2024'\n",
      " '11-06-2024' '24-06-2024' '16-06-2024' '15-06-2024' '22-06-2024'\n",
      " '06-06-2024' '03-06-2024' '10-06-2024' '12-06-2024' '24-07-2024'\n",
      " '13-07-2024' '21-07-2024' '26-07-2024' '15-07-2024' '30-07-2024'\n",
      " '23-07-2024' '08-07-2024' '27-07-2024' '28-07-2024' '17-07-2024'\n",
      " '19-07-2024' '29-07-2024' '22-07-2024' '16-07-2024' '20-07-2024'\n",
      " '11-07-2024' '06-07-2024' '18-07-2024' '25-07-2024' '14-07-2024'\n",
      " '12-07-2024' '10-07-2024' '19-08-2024' '21-08-2024' '14-08-2024'\n",
      " '22-08-2024' '26-08-2024' '18-08-2024' '15-08-2024' '24-08-2024'\n",
      " '23-08-2024' '17-08-2024' '30-08-2024' '11-08-2024' '25-08-2024'\n",
      " '29-08-2024' '08-08-2024' '27-08-2024' '16-08-2024' '13-08-2024'\n",
      " '20-08-2024' '09-08-2024' '28-08-2024' '12-08-2024' '21-09-2024'\n",
      " '16-09-2024' '13-09-2024' '30-09-2024' '12-09-2024' '26-09-2024'\n",
      " '28-09-2024' '25-09-2024' '23-09-2024' '15-09-2024' '10-09-2024'\n",
      " '29-09-2024' '20-09-2024' '18-09-2024' '19-09-2024' '17-09-2024'\n",
      " '22-09-2024' '14-09-2024' '27-09-2024' '24-09-2024' '08-09-2024'\n",
      " '21-10-2024' '10-10-2024' '25-10-2024' '10-11-2024' '18-10-2024'\n",
      " '01-11-2024' '09-10-2024' '07-10-2024' '30-10-2024' '04-10-2024'\n",
      " '21-11-2024' '30-11-2024' '20-11-2024' '18-11-2024' '15-11-2024'\n",
      " '08-11-2024' '22-11-2024' '29-11-2024' '03-12-2024' '17-11-2024'\n",
      " '23-11-2024' '30-12-2024' '18-12-2024' '06-12-2024' '27-12-2024'\n",
      " '13-12-2024' '20-12-2024' '23-12-2024' '28-12-2024' '24-12-2024'\n",
      " '19-12-2024']\n",
      "['03-01-2024' '02-01-2024' '17-01-2024' '06-01-2024' '16-01-2024'\n",
      " '07-01-2024' '15-01-2024' '09-01-2024' '01-01-2024' '18-01-2024'\n",
      " '19-01-2024' '12-01-2024' '04-01-2024' '20-01-2024' '11-01-2024'\n",
      " '10-01-2024' '08-01-2024' '05-01-2024' '14-01-2024' '13-01-2024'\n",
      " '01-02-2024' '03-02-2024' '07-02-2024' '13-02-2024' '05-02-2024'\n",
      " '16-02-2024' '14-02-2024' '15-02-2024' '12-02-2024' '08-02-2024'\n",
      " '06-02-2024' '11-02-2024' '17-02-2024' '04-02-2024' '18-02-2024'\n",
      " '09-02-2024' '19-02-2024' '10-02-2024' '02-02-2024' '20-02-2024'\n",
      " '03-03-2024' '17-03-2024' '18-03-2024' '14-03-2024' '07-03-2024'\n",
      " '04-03-2024' '16-03-2024' '20-03-2024' '10-03-2024' '05-03-2024'\n",
      " '08-03-2024' '19-03-2024' '02-03-2024' '06-03-2024' '01-03-2024'\n",
      " '09-03-2024' '12-03-2024' '11-03-2024' '13-03-2024' '15-03-2024'\n",
      " '18-04-2024' '04-04-2024' '09-04-2024' '10-04-2024' '08-04-2024'\n",
      " '12-04-2024' '19-04-2024' '02-04-2024' '11-04-2024' '15-04-2024'\n",
      " '17-04-2024' '14-04-2024' '03-04-2024' '20-04-2024' '16-04-2024'\n",
      " '05-04-2024' '01-04-2024' '13-04-2024' '07-04-2024' '06-04-2024'\n",
      " '13-05-2024' '01-05-2024' '06-05-2024' '11-05-2024' '10-05-2024'\n",
      " '20-05-2024' '12-05-2024' '15-05-2024' '08-05-2024' '17-05-2024'\n",
      " '16-05-2024' '04-05-2024' '14-05-2024' '09-05-2024' '07-05-2024'\n",
      " '03-05-2024' '19-05-2024' '02-05-2024' '05-05-2024' '13-06-2024'\n",
      " '11-06-2024' '01-06-2024' '20-06-2024' '06-06-2024' '17-06-2024'\n",
      " '15-06-2024' '18-06-2024' '12-06-2024' '10-06-2024' '19-06-2024'\n",
      " '07-06-2024' '08-06-2024' '04-06-2024' '03-06-2024' '05-06-2024'\n",
      " '16-06-2024' '02-06-2024' '14-06-2024' '09-06-2024' '10-07-2024'\n",
      " '06-07-2024' '16-07-2024' '17-07-2024' '05-07-2024' '15-07-2024'\n",
      " '03-07-2024' '18-07-2024' '12-07-2024' '07-07-2024' '02-07-2024'\n",
      " '14-07-2024' '09-07-2024' '13-07-2024' '08-07-2024' '11-07-2024'\n",
      " '04-07-2024' '19-07-2024' '01-07-2024' '20-07-2024' '17-08-2024'\n",
      " '16-08-2024' '11-08-2024' '14-08-2024' '13-08-2024' '18-08-2024'\n",
      " '08-08-2024' '19-08-2024' '10-08-2024' '02-08-2024' '06-08-2024'\n",
      " '12-08-2024' '20-08-2024' '03-08-2024' '09-08-2024' '07-08-2024'\n",
      " '15-08-2024' '05-08-2024' '01-08-2024' '01-09-2024' '15-09-2024'\n",
      " '12-09-2024' '16-09-2024' '08-09-2024' '13-09-2024' '11-09-2024'\n",
      " '06-09-2024' '07-09-2024' '19-09-2024' '17-09-2024' '04-09-2024'\n",
      " '05-09-2024' '09-09-2024' '20-09-2024' '18-09-2024' '14-09-2024'\n",
      " '10-09-2024' '02-09-2024' '03-09-2024' '10-10-2024' '18-10-2024'\n",
      " '04-10-2024' '25-10-2024' '01-11-2024' '09-10-2024' '27-09-2024'\n",
      " '22-11-2024' '15-11-2024' '29-11-2024' '08-11-2024' '08-12-2024'\n",
      " '27-12-2024' '06-12-2024' '13-12-2024' '20-12-2024']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Reimbursement_cleaned_data.csv\")\n",
    "\n",
    "# Print unique values in 'Claim Date' and 'Bill_Date' to check for issues\n",
    "print(df[\"Claim Date\"].unique())\n",
    "print(df[\"Bill_Date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Invalid Dates:\n",
      "    Claim Date Employee Name  Employee ID        Designation  \\\n",
      "107        NaT   Mila Palmer         1996     Talent Partner   \n",
      "148        NaT  Jonah Hughes         2089     Data Scientist   \n",
      "150        NaT   Tobin Green         1935     Data Scientist   \n",
      "160        NaT  Maddox Perez         2011         Associate    \n",
      "161        NaT  Mabel Gibson         2008  Software Engineer   \n",
      "\n",
      "          Project Name         Email address  Total Persons  Allowable Amount  \\\n",
      "107                  -   Mila.Palmer@xyz.com              2               800   \n",
      "148                 o9  Jonah.Hughes@xyz.com              1               400   \n",
      "150        TripAdvisor   Tobin.Green@xyz.com             11              4400   \n",
      "160  LTV - Tripadvisor  Maddox.Perez@xyz.com              8              3200   \n",
      "161          greenMath  Mabel.Gibson@xyz.com              7              2800   \n",
      "\n",
      "    Total Bill Amount                          List of Persons (as JSON)  \\\n",
      "107               831  [{\"employee_code\": \"1996\", \"name\": \"Mila Palme...   \n",
      "148               385  [{\"employee_code\": \"2089\", \"name\": \"Jonah Hugh...   \n",
      "150              4443  [{\"employee_code\": \"1935\", \"name\": \"Tobin Gree...   \n",
      "160              3163  [{\"employee_code\": \"2011\", \"name\": \"Maddox Per...   \n",
      "161              2876  [{\"employee_code\": \"2008\", \"name\": \"Mabel Gibs...   \n",
      "\n",
      "    Seating Location  Bill_Date Bill_No Bill day  Computed_Total_Persons  \\\n",
      "107          Chennai 2024-02-16   02_63   Friday                       2   \n",
      "148          Chennai 2024-02-04  02_159   Sunday                       1   \n",
      "150          Chennai 2024-02-19   02_12   Monday                      65   \n",
      "160          Chennai 2024-02-19    02_7   Monday                       8   \n",
      "161          Chennai 2024-02-09  02_128   Friday                       8   \n",
      "\n",
      "     Mismatch  \n",
      "107     False  \n",
      "148     False  \n",
      "150      True  \n",
      "160     False  \n",
      "161      True  \n"
     ]
    }
   ],
   "source": [
    "df[\"Claim Date\"] = pd.to_datetime(df[\"Claim Date\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"Bill_Date\"] = pd.to_datetime(df[\"Bill_Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# Check if any dates failed to convert\n",
    "invalid_dates = df[df[\"Claim Date\"].isna() | df[\"Bill_Date\"].isna()]\n",
    "print(\"Rows with Invalid Dates:\")\n",
    "print(invalid_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Claim Date\", \"Bill_Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where 'Bill Date' does not match 'Bill Day': 0\n",
      "Validation results saved to 'validated_file.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Convert Bill_Date column to datetime format\n",
    "df['Bill_Date'] = pd.to_datetime(df['Bill_Date'], errors='coerce')\n",
    "\n",
    "# Extract weekday names from Bill_Date\n",
    "df['Calculated_Bill_Day'] = df['Bill_Date'].dt.day_name()\n",
    "\n",
    "# Compare with the Bill Day column\n",
    "df['Bill_Day_Match'] = df['Calculated_Bill_Day'] == df['Bill day']\n",
    "\n",
    "# Count mismatched rows\n",
    "num_mismatches = df['Bill_Day_Match'].value_counts().get(False, 0)\n",
    "\n",
    "print(f\"Number of rows where 'Bill Date' does not match 'Bill Day': {num_mismatches}\")\n",
    "\n",
    "# Save the results if needed\n",
    "df.to_csv(\"datechk_file.csv\", index=False)\n",
    "\n",
    "print(\"Validation results saved to 'validated_file.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatched Bill Dates and Bill Days: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert Bill_Date column to datetime format\n",
    "df['Bill_Date'] = pd.to_datetime(df['Bill_Date'], errors='coerce')\n",
    "\n",
    "# Dictionary to map weekday names to their corresponding weekday numbers\n",
    "weekday_mapping = {\n",
    "    \"Monday\": 0, \"Tuesday\": 1, \"Wednesday\": 2, \"Thursday\": 3,\n",
    "    \"Friday\": 4, \"Saturday\": 5, \"Sunday\": 6\n",
    "}\n",
    "\n",
    "# Check if the weekday of Bill_Date matches the expected weekday from Bill Day\n",
    "df['Bill_Day_Valid'] = df.apply(lambda row: row['Bill_Date'].weekday() == weekday_mapping.get(row['Bill day'], -1), axis=1)\n",
    "\n",
    "# Count mismatches\n",
    "num_mismatches = df['Bill_Day_Valid'].value_counts().get(False, 0)\n",
    "\n",
    "print(f\"Number of mismatched Bill Dates and Bill Days: {num_mismatches}\")\n",
    "\n",
    "# Save results to a new CSV file\n",
    "df.to_csv(\"bill_date_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Reimbursement_cleaned_data.csv\"  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete! Data saved to 'updated_bill_claim_data.csv'\n",
      "Number of times Bill Date is ahead of Claim Date: 0\n"
     ]
    }
   ],
   "source": [
    "df['Bill_Date'] = pd.to_datetime(df['Bill_Date'], format='%d-%m-%Y', errors='coerce')\n",
    "df['Claim Date'] = pd.to_datetime(df['Claim Date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# Function to map Bill_Date to the correct Friday, ensuring it stays in 2024\n",
    "def adjust_to_friday(bill_date):\n",
    "    if pd.isnull(bill_date):\n",
    "        return None  # Handle missing dates\n",
    "    \n",
    "    # Get the previous Friday\n",
    "    previous_friday = bill_date - pd.DateOffset(days=(bill_date.weekday() - 4) % 7)\n",
    "\n",
    "    # Ensure the date stays within 2024\n",
    "    if previous_friday.year < 2024:\n",
    "        return previous_friday + pd.DateOffset(days=7)  # Move to next Friday in 2024\n",
    "    elif previous_friday.year > 2024:\n",
    "        return previous_friday - pd.DateOffset(days=7)  # Move to previous Friday in 2024\n",
    "\n",
    "    return previous_friday\n",
    "\n",
    "# Apply function to create new Bill_Date_Friday column\n",
    "df['Bill_Date_Friday'] = df['Bill_Date'].apply(adjust_to_friday)\n",
    "\n",
    "# Replace Claim Date if it occurs before Bill_Date_Friday\n",
    "df['Claim Date'] = df.apply(lambda row: row['Bill_Date_Friday'] if row['Claim Date'] < row['Bill_Date_Friday'] else row['Claim Date'], axis=1)\n",
    "\n",
    "# Fill missing Seating Location with \"Chennai\"\n",
    "df['Seating Location'] = df['Seating Location'].fillna(\"Chennai\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"updated_bill_claim_data.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete! Data saved to 'updated_bill_claim_data.csv'\")\n",
    "\n",
    "bill_ahead_count = (df['Bill_Date_Friday'] > df['Claim Date']).sum()\n",
    "\n",
    "print(f\"Number of times Bill Date is ahead of Claim Date: {bill_ahead_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
